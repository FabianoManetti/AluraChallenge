{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Alura Challenge - Semana 03"
      ],
      "metadata": {
        "id": "OTptr4Qu9xq7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDIQBqdz-kfP"
      },
      "source": [
        "## Objetivos deste trabalho"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWBO_Zsr-kfQ"
      },
      "source": [
        "•\tVerificar se a variável target está balanceada;\n",
        "\n",
        "•\tAplicar encoding nos seus dados;\n",
        "\n",
        "•\tCriar dois ou mais modelos de Machine Learning;\n",
        "\n",
        "•\tAvaliar cada modelo utilizando métricas de ML;\n",
        "\n",
        "•\tEscolher o melhor modelo;\n",
        "\n",
        "•\tOtimizar o melhor modelo;\n",
        "\n",
        "•\tVerificar qual o melhor tipo de balanceamento com esses dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIlcgzNm-kfQ"
      },
      "source": [
        "## Verificando o balanceamento da variável target Churn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTAq0VCB-kfR",
        "outputId": "31eda447-0ade-4b79-fe0b-3b52516d9de7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    73.46\n",
              "1    26.54\n",
              "Name: Churn, dtype: float64"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "proporcao_churn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya10H-UF-kfR"
      },
      "source": [
        "<p style='font-size: 16px; line-height: 2; margin: 10px 50px; text-align: justify;'>Conforme já anteriormente observado, a variável target Churn está dividida em, aproximadamente, 73,5% 'Não' e 26,5% 'Sim' dos dados do nosso dataset. Desta forma, há um desbalanceamento entre estes valores, o que poderá ocasionar enviesamento e conseguinte interferência no nosso modelo de previsão. Para mitigar este efeito, utilizaremos algumas técnicas de rebalanceamentos de dados: </p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8pDl-l7-kfS"
      },
      "source": [
        "## Tratando o desbalanceamento da variável target Churn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFev_f9q-kfS"
      },
      "source": [
        "<p style='font-size: 16px; line-height: 2; margin: 10px 50px; text-align: justify;'>Para tratarmos o desbalanceamento da nossa variável target, duas técnicas consagradas poderão ser utilizadas: undersampling (redução da quantidade de dados do valor 'Não') e oversampling' (ampliação dos dados do valor 'Sim'). Ambas técnicas possuem vantagens e desvantagens intrínsecas. Para este trabalho, iremos avaliar as duas possibilidades de modo a comparar o resultado final obtido em cada técnica. Após o balanceamento, iremos proceder com a normalização dos dados numéricos, uma vez que eles se encontram em escalas diferentes entre si e entre as demais features.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX-8g5sj9nfg"
      },
      "source": [
        "## Definindo as variáveis dos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz5l8EJW9nfg"
      },
      "outputs": [],
      "source": [
        "y = df_churn['Churn']\n",
        "X = df_churn[['Idoso', 'Dependentes', 'Meses_Contrato', 'Internet', 'Fatura_Online', 'Gasto_Mensal', 'Gasto_Total', 'Parceiro',\n",
        "                      'Mensal', 'Bianual', 'Cartao_credito', 'Boleto_eletronico', 'Boleto_correios', 'Transf_banco', 'Anual']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1XDcpyx9nfg"
      },
      "outputs": [],
      "source": [
        "features_numericas = ['Meses_Contrato', 'Gasto_Total', 'Gasto_Mensal']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMYFLCgO-kfX"
      },
      "source": [
        "## Criando modelos de Machine Learning para predizer o Churn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiUTrHOC-kfX"
      },
      "source": [
        "<p style='font-size: 16px; line-height: 2; margin: 10px 50px; text-align: justify;'>Estamos aptos, neste momento, a criar nossos modelos preditivos baseados nas features previamente selecionadas e nas variáveis balanceadas. Optamos por utilizar os principais modelos de machine learning de classificação: Logistic Regression, Random Forest Classifier, Decision Tree Classifier, Gradient Boosting Classifier e Support Vector Classifier. Antes, porém, iremos iniciar com o modelo comparador DummyClassifier. Obs.: Nossas features foram previamente classificadas numericamente em 0 e 1 (para as variáveis originalmente categóricas do nosso dataset). Desta forma, não será necessário utilizarmos Enconding no dataframe. Utilizaremos o método cross_validate para realizarmos a validação cruzada dos modelos e reduzirmos o fator de aleatoriedade, juntamente com o método Pipeline, que irá agrupar as funções de balanceamento, normalização e treino do modelo. Esta é uma boa prática para reduzirmos, também, o chamado 'data leakage' e o conseguinte enviesamento dos modelos.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd5ZgJLH9nfg"
      },
      "outputs": [],
      "source": [
        "modelos = {'Logistic Regression': LogisticRegression(random_state = 53, max_iter = 200, solver = 'lbfgs'), \n",
        "           'Random Forest Classifier': RandomForestClassifier(random_state = 53, max_depth = 15, n_estimators = 100),\n",
        "           'Decision Tree Classifier': DecisionTreeClassifier(random_state = 53, max_depth = 6, criterion = 'gini'),\n",
        "           'Gradient Boosting Classifier': GradientBoostingClassifier(n_estimators = 100, max_depth = 3, min_samples_split = 2,\n",
        "                                                              learning_rate = 0.1, random_state = 53),\n",
        "           'Support Vector Classifier': svm.SVC(kernel = 'rbf', random_state = 53)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-ub6l_U-kfY"
      },
      "source": [
        "### DummyClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NX6JzeAW-kfZ"
      },
      "outputs": [],
      "source": [
        "X_dummy = X.copy()\n",
        "y_dummy = y.copy()\n",
        "\n",
        "original = []\n",
        "predito = []\n",
        "\n",
        "def classification_report_accuracy_score(y_real, y_pred):\n",
        "    original.extend(y_real)\n",
        "    predito.extend(y_pred)\n",
        "    return accuracy_score(y_real, y_pred)\n",
        "\n",
        "modelo_dummy = DummyClassifier(strategy = 'stratified', random_state = 53)\n",
        "\n",
        "resultado_dummy = cross_validate(modelo_dummy, X_dummy, y_dummy, cv = 10, return_train_score = False,\n",
        "                  scoring = make_scorer(classification_report_accuracy_score))\n",
        "report_dummy = (classification_report(original, predito))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opJDIcQf-kfS"
      },
      "source": [
        "### Undersampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61d1GvJr-kfT"
      },
      "source": [
        "<p style='font-size: 16px; line-height: 2; margin: 10px 50px; text-align: justify;'>Para a técnica de Undersampling, utilizaremos o método NearMiss, que considera a menor distância média entre K-vizinhos mais próximos.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYaDBUPa9nfh"
      },
      "outputs": [],
      "source": [
        "X_undersampling = X.copy()\n",
        "y_undersampling = y.copy()\n",
        "\n",
        "original = []\n",
        "predito = []\n",
        "\n",
        "def classification_report_accuracy_score(y_real, y_pred):\n",
        "    original.extend(y_real)\n",
        "    predito.extend(y_pred)\n",
        "    return accuracy_score(y_real, y_pred)\n",
        "\n",
        "resultado_undersampling = {}\n",
        "report_undersampling = {}\n",
        "\n",
        "for nome, modelo in modelos.items():\n",
        "    \n",
        "    undersampling = NearMiss(version = 2)\n",
        "    scaler = MinMaxScaler()\n",
        "    modelo_tipo = modelo\n",
        "    \n",
        "    pipeline = Pipeline([('balanceamento', undersampling), ('normalizacao', scaler), ('modelo', modelo_tipo)])\n",
        "    \n",
        "    cv = StratifiedKFold(n_splits = 10, shuffle=True)\n",
        "    resultado_undersampling[nome] = cross_validate(pipeline, X_undersampling, y_undersampling, cv = cv, \n",
        "                                    return_train_score = False, scoring = make_scorer(classification_report_accuracy_score))\n",
        "    report_undersampling[nome] = (classification_report(original, predito))\n",
        "    original = []\n",
        "    predito = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQTQsz4D-kfU"
      },
      "source": [
        "### Oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6akd9DhO-kfV"
      },
      "source": [
        "<p style='font-size: 16px; line-height: 2; margin: 10px 50px; text-align: justify;'>Para a técnica de Oversampling, utilizaremos o método SMOTE, que cria dados sintéticos para a classe de menor quantidade proporcional de dados.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a1r3PL_9nfh"
      },
      "outputs": [],
      "source": [
        "X_oversampling = X.copy()\n",
        "y_oversampling = y.copy()\n",
        "\n",
        "original = []\n",
        "predito = []\n",
        "\n",
        "def classification_report_accuracy_score(y_real, y_pred):\n",
        "    original.extend(y_real)\n",
        "    predito.extend(y_pred)\n",
        "    return accuracy_score(y_real, y_pred)\n",
        "\n",
        "resultado_oversampling = {}\n",
        "report_oversampling = {}\n",
        "\n",
        "for nome, modelo in modelos.items():\n",
        "    \n",
        "    oversampling = SMOTE(random_state = 53, k_neighbors = 5)\n",
        "    scaler = MinMaxScaler()\n",
        "    modelo_tipo = modelo\n",
        "    \n",
        "    pipeline = Pipeline([('balanceamento', oversampling), ('normalizacao', scaler), ('modelo', modelo_tipo)])\n",
        "    \n",
        "    cv = StratifiedKFold(n_splits = 10, shuffle=True)\n",
        "    resultado_oversampling[nome] = cross_validate(pipeline, X_oversampling, y_oversampling, cv = cv, \n",
        "                                   return_train_score = False, scoring = make_scorer(classification_report_accuracy_score))\n",
        "    report_oversampling[nome] = (classification_report(original, predito))\n",
        "    original = []\n",
        "    predito = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPECEF2H-kfr"
      },
      "source": [
        "## Avaliando os modelos criados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve5UDhAt-kfr"
      },
      "source": [
        "<p style='font-size: 16px; line-height: 2; margin: 10px 50px; text-align: justify;'>Uma vez instanciados e treinados os modelos, podemos partir para a avaliação dos mesmos. Para tanto, nos valeremos do método classification_report da biblioteca sklearn, a qual disponibiliza algumas métricas importantes como a Precisão (do total de usuários que o modelo previu como positivos, quantos realmente eram positivos), Revocação (do total de usuários que realmente eram positivos, quantos o modelo previu como positivos) e f1-score (média harmônica enter a Precisão e a Revocação). Além disto, vamos avaliar também o intervalo (95% de confiança) relativo ao score para os dados de teste. Primeiramente, iremos avaliar nosso modelo comparador DummyClassifier:</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL6QyeeftPJH"
      },
      "source": [
        "### DummyClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdzbuRgxtY_y",
        "outputId": "48b93758-8439-49d6-cca1-bd3b827062b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.76      5174\n",
            "           1       0.26      0.22      0.24      1869\n",
            "\n",
            "    accuracy                           0.63      7043\n",
            "   macro avg       0.50      0.50      0.50      7043\n",
            "weighted avg       0.61      0.63      0.62      7043\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(report_dummy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLZw-sWu9nfi",
        "outputId": "14275a68-f29c-415d-c56f-ecd31d68a02a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intervalo Accuracy teste: [60.92, 65.11]\n"
          ]
        }
      ],
      "source": [
        "media = resultado_dummy['test_score'].mean()\n",
        "desvio_padrao = resultado_dummy['test_score'].std()\n",
        "print(\"Intervalo Accuracy teste: [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, (media + 2 * desvio_padrao) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAV1FG9D9nfi"
      },
      "source": [
        "<p style='font-size: 16px; line-height: 2; margin: 10px 50px; text-align: justify;'>Aqui, podemos perceber claramente a necessidade de balanceamento dos dados: a acurácia do modelo Dummy Classifier foi de 0.60, porém analisando especificamente as métricas relativas ao Churn 'Sim' (ou 1), verificamos que há um claro enviesamento do modelo em favor do valor 'Não', indo ao encontro da proporção anteriormente calculada.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZMPb1nH9nfi"
      },
      "source": [
        "### Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-Ir109s9nfi",
        "outputId": "ab15a9c0-56e9-4a91-bedb-e58d4633d577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.50      0.64      5174\n",
            "           1       0.37      0.83      0.51      1869\n",
            "\n",
            "    accuracy                           0.59      7043\n",
            "   macro avg       0.63      0.66      0.58      7043\n",
            "weighted avg       0.75      0.59      0.61      7043\n",
            "\n",
            "Random Forest Classifier:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.34      0.48      5174\n",
            "           1       0.31      0.82      0.45      1869\n",
            "\n",
            "    accuracy                           0.47      7043\n",
            "   macro avg       0.58      0.58      0.47      7043\n",
            "weighted avg       0.70      0.47      0.48      7043\n",
            "\n",
            "Decision Tree Classifier:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.34      0.48      5174\n",
            "           1       0.30      0.78      0.44      1869\n",
            "\n",
            "    accuracy                           0.46      7043\n",
            "   macro avg       0.56      0.56      0.46      7043\n",
            "weighted avg       0.68      0.46      0.47      7043\n",
            "\n",
            "Gradient Boosting Classifier:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.35      0.49      5174\n",
            "           1       0.31      0.81      0.45      1869\n",
            "\n",
            "    accuracy                           0.47      7043\n",
            "   macro avg       0.57      0.58      0.47      7043\n",
            "weighted avg       0.69      0.47      0.48      7043\n",
            "\n",
            "Support Vector Classifier:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.49      0.63      5174\n",
            "           1       0.36      0.78      0.49      1869\n",
            "\n",
            "    accuracy                           0.57      7043\n",
            "   macro avg       0.61      0.64      0.56      7043\n",
            "weighted avg       0.73      0.57      0.59      7043\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for nome, report in report_undersampling.items():\n",
        "    print(f'{nome}:\\n')\n",
        "    print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bz6UStiV9nfi",
        "outputId": "6e419474-f17e-438d-8883-36db230dba4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Intervalo Accuracy teste: [55.48, 61.92]', 'Logistic Regression')\n",
            "('Intervalo Accuracy teste: [41.27, 52.42]', 'Random Forest Classifier')\n",
            "('Intervalo Accuracy teste: [42.24, 50.08]', 'Decision Tree Classifier')\n",
            "('Intervalo Accuracy teste: [44.63, 48.88]', 'Gradient Boosting Classifier')\n",
            "('Intervalo Accuracy teste: [52.60, 61.24]', 'Support Vector Classifier')\n"
          ]
        }
      ],
      "source": [
        "lista_valores = []\n",
        "for i in resultado_undersampling.values():\n",
        "    media = i['test_score'].mean()\n",
        "    desvio_padrao = i['test_score'].std()\n",
        "    lista_valores.append(\"Intervalo Accuracy teste: [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, \n",
        "                                                             (media + 2 * desvio_padrao) * 100))\n",
        "lista_nomes = []\n",
        "for i in resultado_undersampling.keys():\n",
        "    lista_nomes.append(i)    \n",
        "\n",
        "merged_lista = tuple(zip(lista_valores, lista_nomes))\n",
        "\n",
        "for i in merged_lista:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qty5zwPZ9nfj"
      },
      "source": [
        "### Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gpw1vczI9nfj",
        "outputId": "a45a21a1-d716-4071-adb2-fa65a3ba5aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.81      0.84      5174\n",
            "           1       0.56      0.68      0.62      1869\n",
            "\n",
            "    accuracy                           0.77      7043\n",
            "   macro avg       0.72      0.75      0.73      7043\n",
            "weighted avg       0.79      0.77      0.78      7043\n",
            "\n",
            "Random Forest Classifier:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.82      0.84      5174\n",
            "           1       0.56      0.63      0.59      1869\n",
            "\n",
            "    accuracy                           0.77      7043\n",
            "   macro avg       0.71      0.73      0.72      7043\n",
            "weighted avg       0.78      0.77      0.77      7043\n",
            "\n",
            "Decision Tree Classifier:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.82      5174\n",
            "           1       0.52      0.71      0.60      1869\n",
            "\n",
            "    accuracy                           0.75      7043\n",
            "   macro avg       0.70      0.73      0.71      7043\n",
            "weighted avg       0.78      0.75      0.76      7043\n",
            "\n",
            "Gradient Boosting Classifier:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.81      0.84      5174\n",
            "           1       0.56      0.67      0.61      1869\n",
            "\n",
            "    accuracy                           0.77      7043\n",
            "   macro avg       0.72      0.74      0.73      7043\n",
            "weighted avg       0.79      0.77      0.78      7043\n",
            "\n",
            "Support Vector Classifier:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.80      0.83      5174\n",
            "           1       0.55      0.65      0.59      1869\n",
            "\n",
            "    accuracy                           0.76      7043\n",
            "   macro avg       0.71      0.73      0.71      7043\n",
            "weighted avg       0.78      0.76      0.77      7043\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for nome, report in report_oversampling.items():\n",
        "    print(f'{nome}:\\n')\n",
        "    print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q31Zpe049nfj",
        "outputId": "b24a1f8d-f6bf-44ff-fe53-4bb1b4645909"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Intervalo Accuracy teste: [74.84, 80.01]', 'Logistic Regression')\n",
            "('Intervalo Accuracy teste: [73.36, 80.81]', 'Random Forest Classifier')\n",
            "('Intervalo Accuracy teste: [71.93, 77.43]', 'Decision Tree Classifier')\n",
            "('Intervalo Accuracy teste: [74.02, 80.97]', 'Gradient Boosting Classifier')\n",
            "('Intervalo Accuracy teste: [73.22, 79.64]', 'Support Vector Classifier')\n"
          ]
        }
      ],
      "source": [
        "lista_valores = []\n",
        "for i in resultado_oversampling.values():\n",
        "    media = i['test_score'].mean()\n",
        "    desvio_padrao = i['test_score'].std()\n",
        "    lista_valores.append(\"Intervalo Accuracy teste: [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, \n",
        "                                                             (media + 2 * desvio_padrao) * 100))\n",
        "lista_nomes = []\n",
        "for i in resultado_oversampling.keys():\n",
        "    lista_nomes.append(i)    \n",
        "\n",
        "merged_lista = tuple(zip(lista_valores, lista_nomes))\n",
        "\n",
        "for i in merged_lista:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zf_yxvm9nfj"
      },
      "source": [
        "## Escolhendo o melhor modelo e o tipo de balanceamento mais adequado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQAZtWpI9nfj"
      },
      "source": [
        "<p style='font-size: 16px; line-height: 2; margin: 10px 50px; text-align: justify;'>Para nosso problema principal de redução da taxa de churn dos clientes da Alura Voz, queremos otimizar a identificação dos clientes com propensão a evadir do serviço, de modo a tentarmos estratégias comerciais de retenção dos mesmos na base. Sendo assim, diante dos resultados apresentados anteriormente, podemos perceber que o modelo Gradient Boosting Classifier, juntamente com a técnica oversampling, apresentou o melhor score integrado, seja de precisão, seja de revocação. Portanto, este será o modelo escolhido para o nosso dataset.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdZn1bJw9nfj"
      },
      "source": [
        "## Otimizando o melhor modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y57tMM8p9nfj"
      },
      "source": [
        "<p style='font-size: 16px; line-height: 2; margin: 10px 50px; text-align: justify;'>Podemos, ainda, tentar otimizar os hiperparâmetros do nosso modelo escolhido e avaliar a sua performance com os dados balanceados. Para isto, utilizaremos a biblioteca GridSearchCV, que realiza a validação cruzada para cada variação dos parâmetros escolhidos.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmjRKPhP9nfj"
      },
      "outputs": [],
      "source": [
        "modelo_escolhido = GradientBoostingClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5HArR1d9nfj"
      },
      "outputs": [],
      "source": [
        "hiperparametros = {'modelo__n_estimators': [100, 125, 150, 200],\n",
        "                   'modelo__max_depth': [3, 4, 5, 6],\n",
        "                   'modelo__min_samples_split': [2, 3],\n",
        "                   'modelo__learning_rate': [0.1, 1]}\n",
        "\n",
        "oversampling = SMOTE(random_state = 53, k_neighbors = 5)\n",
        "scaler = MinMaxScaler()\n",
        "    \n",
        "pipeline = Pipeline([('balanceamento', oversampling), ('normalizacao', scaler), ('modelo', modelo_escolhido)])\n",
        "    \n",
        "cv = StratifiedKFold(n_splits = 10, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "f-LFgQP59nfj",
        "outputId": "ebe5495b-e9a8-4d40-c652-772b1a243b44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=True),\n",
              "             estimator=Pipeline(steps=[('balanceamento',\n",
              "                                        SMOTE(random_state=53)),\n",
              "                                       ('normalizacao', MinMaxScaler()),\n",
              "                                       ('modelo',\n",
              "                                        GradientBoostingClassifier())]),\n",
              "             param_grid={'modelo__learning_rate': [0.1, 1],\n",
              "                         'modelo__max_depth': [3, 4, 5, 6],\n",
              "                         'modelo__min_samples_split': [2, 3],\n",
              "                         'modelo__n_estimators': [100, 125, 150, 200]})"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "otimiz = GridSearchCV(pipeline, hiperparametros, cv = cv)\n",
        "otimiz.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRHZePPh9nfj",
        "outputId": "c08845b6-5112-4607-b6d1-21170118d31f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'modelo__learning_rate': 0.1, 'modelo__max_depth': 5, 'modelo__min_samples_split': 2, 'modelo__n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "best_par = otimiz.best_params_\n",
        "print(best_par)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Lv4GIFJ9nfj"
      },
      "outputs": [],
      "source": [
        "modelo_churn_otimizado = GradientBoostingClassifier(max_depth = best_par['modelo__max_depth'],\n",
        "                                                    min_samples_split = best_par['modelo__min_samples_split'], \n",
        "                                                    n_estimators = best_par['modelo__n_estimators'],\n",
        "                                                    learning_rate = best_par['modelo__learning_rate'], random_state = 53)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzBExFiG9nfk"
      },
      "source": [
        "<p style='font-size: 16px; line-height: 2; margin: 10px 50px; text-align: justify;'>De posse dos parâmetros otimizados para o nosso modelo escolhido, iremos realizar uma nova validação cruzada a fim de reduzir a aleatoriedade e o possível vazamento de dados oriundos do processo de otimização de hiperparâmetros:</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TODqc3mI9nfk"
      },
      "source": [
        "## Verificando o modelo final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "QVFqjFuG9nfk",
        "outputId": "51060e18-3781-4f8c-9911-d8415f9f1e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.83      0.85      5174\n",
            "           1       0.58      0.63      0.60      1869\n",
            "\n",
            "    accuracy                           0.78      7043\n",
            "   macro avg       0.72      0.73      0.73      7043\n",
            "weighted avg       0.79      0.78      0.78      7043\n",
            "\n",
            "Intervalo Accuracy teste: [75.18, 80.78]\n"
          ]
        }
      ],
      "source": [
        "original = []\n",
        "predito = []\n",
        "\n",
        "def classification_report_accuracy_score(y_real, y_pred):\n",
        "    original.extend(y_real)\n",
        "    predito.extend(y_pred)\n",
        "    return accuracy_score(y_real, y_pred)\n",
        "\n",
        "oversampling = SMOTE(random_state = 53, k_neighbors = 5)\n",
        "scaler = MinMaxScaler()\n",
        "    \n",
        "pipeline = Pipeline([('balanceamento', oversampling), ('normalizacao', scaler), ('modelo', modelo_churn_otimizado)])\n",
        "    \n",
        "cv = StratifiedKFold(n_splits = 10, shuffle=True)\n",
        "\n",
        "scores = cross_val_score(pipeline, X, y, cv = cv, scoring = make_scorer(classification_report_accuracy_score))\n",
        "\n",
        "print(classification_report(original, predito))\n",
        "media = scores.mean()\n",
        "desvio_padrao = scores.std()\n",
        "print(\"Intervalo Accuracy teste: [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, (media + 2 * desvio_padrao) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEjWsolMp0go"
      },
      "source": [
        "<p style='font-size: 16px; line-height: 2; margin: 10px 50px; text-align: justify;'>Percebemos que houve uma melhora discreta na qualidade de predição do nosso modelo escohido, com destaque para a redução da diferença dos valores no intervalo de confiança. Por fim, iremos salvar o modelo otimizado para posterior deployment.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u7EYvHW9nfk",
        "outputId": "fa3a1cf1-d1f0-4edc-95b8-11f03b2f4487"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['modelo_churn.sav']"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filename = 'modelo_churn.sav'\n",
        "joblib.dump(modelo_churn_otimizado, filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Alura_Challenge_Semana_03_atualizado.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}